{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"scrape\"\n",
        "eval: false\n",
        "---"
      ],
      "id": "59d27992"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "\n",
        "def get_nhl_stats(team_code, year, month, session_cookie=None):\n",
        "    \"\"\"\n",
        "    Scrape NHL player stats from Natural Stat Trick for a specific team and month.\n",
        "    \n",
        "    Args:\n",
        "        team_code (str): The three-letter team code (e.g., 'VAN' for Vancouver)\n",
        "        year (int): The year (e.g., 2025)\n",
        "        month (int): The month (1-12)\n",
        "        session_cookie (str, optional): Your Natural Stat Trick session cookie for premium access\n",
        "    \n",
        "    Returns:\n",
        "        pandas.DataFrame: Player statistics for the specified period\n",
        "    \"\"\"\n",
        "    # Calculate the first and last day of the month\n",
        "    first_day = f\"{year}-{month:02d}-01\"\n",
        "    \n",
        "    # Simple way to get last day of month\n",
        "    if month == 12:\n",
        "        next_month_year = year + 1\n",
        "        next_month = 1\n",
        "    else:\n",
        "        next_month_year = year\n",
        "        next_month = month + 1\n",
        "    \n",
        "    last_day_obj = datetime(next_month_year, next_month, 1)\n",
        "    last_day_obj = last_day_obj.replace(day=1) - pd.Timedelta(days=1)\n",
        "    last_day = last_day_obj.strftime(\"%Y-%m-%d\")\n",
        "    \n",
        "    # Determine the season\n",
        "    if month >= 9:  # NHL season starts in October, so September is part of the new season\n",
        "        season_start = year\n",
        "        season_end = year + 1\n",
        "    else:\n",
        "        season_start = year - 1\n",
        "        season_end = year\n",
        "    \n",
        "    season = f\"{season_start}{season_end}\"\n",
        "    \n",
        "    url = (f\"https://www.naturalstattrick.com/playerteams.php?\"\n",
        "           f\"fromseason={season}&thruseason={season}&stype=2&sit=all&score=all&\"\n",
        "           f\"stdoi=oi&rate=n&team={team_code}&pos=S&loc=B&toi=0&\"\n",
        "           f\"gpfilt=gpdate&fd={first_day}&td={last_day}&tgp=5&lines=single&draftteam=ALL\")\n",
        "    \n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    }\n",
        "    \n",
        "    # Add session cookie if provided (needed for premium features)\n",
        "    cookies = {}\n",
        "    if session_cookie:\n",
        "        cookies['PHPSESSID'] = session_cookie\n",
        "    \n",
        "    response = requests.get(url, headers=headers, cookies=cookies)\n",
        "    \n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Failed to fetch data: Status code {response.status_code}\")\n",
        "    \n",
        "    # Parse the HTML\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    \n",
        "    # Find the stats table\n",
        "    table = soup.find('table', {'id': 'playerTable'})\n",
        "    \n",
        "    if not table:\n",
        "        raise Exception(\"Could not find the player stats table on the page\")\n",
        "    \n",
        "    # Extract headers\n",
        "    headers = []\n",
        "    for th in table.find('thead').find_all('th'):\n",
        "        headers.append(th.text.strip())\n",
        "    \n",
        "    # Extract rows\n",
        "    rows = []\n",
        "    for tr in table.find('tbody').find_all('tr'):\n",
        "        row = []\n",
        "        for td in tr.find_all('td'):\n",
        "            row.append(td.text.strip())\n",
        "        rows.append(row)\n",
        "    \n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(rows, columns=headers)\n",
        "    \n",
        "    # Add metadata\n",
        "    df['team'] = team_code\n",
        "    df['year'] = year\n",
        "    df['month'] = month\n",
        "    df['url'] = url\n",
        "    \n",
        "    return df\n",
        "\n",
        "def scrape_multiple_months(team_code, start_year, start_month, end_year, end_month, session_cookie=None):\n",
        "    \"\"\"\n",
        "    Scrape data for multiple consecutive months\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    current_year, current_month = start_year, start_month\n",
        "    \n",
        "    while (current_year < end_year) or (current_year == end_year and current_month <= end_month):\n",
        "        print(f\"Scraping {team_code} data for {current_year}-{current_month:02d}...\")\n",
        "        try:\n",
        "            df = get_nhl_stats(team_code, current_year, current_month, session_cookie)\n",
        "            all_data.append(df)\n",
        "            print(f\"Found {len(df)} player records\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {current_year}-{current_month:02d}: {e}\")\n",
        "        \n",
        "        # Move to next month\n",
        "        if current_month == 12:\n",
        "            current_month = 1\n",
        "            current_year += 1\n",
        "        else:\n",
        "            current_month += 1\n",
        "        \n",
        "        # Be nice to the server\n",
        "        time.sleep(2)\n",
        "    \n",
        "    if all_data:\n",
        "        return pd.concat(all_data, ignore_index=True)\n",
        "    return pd.DataFrame()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='Scrape NHL player stats from Natural Stat Trick')\n",
        "    parser.add_argument('team', type=str, help='Three-letter team code (e.g., VAN)')\n",
        "    parser.add_argument('--start-year', type=int, required=True, help='Starting year (e.g., 2024)')\n",
        "    parser.add_argument('--start-month', type=int, required=True, help='Starting month (1-12)')\n",
        "    parser.add_argument('--end-year', type=int, required=True, help='Ending year (e.g., 2025)')\n",
        "    parser.add_argument('--end-month', type=int, required=True, help='Ending month (1-12)')\n",
        "    parser.add_argument('--session', type=str, help='Your Natural Stat Trick session cookie (for premium access)')\n",
        "    parser.add_argument('--output', type=str, default='nhl_stats.csv', help='Output CSV filename')\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    df = scrape_multiple_months(\n",
        "        args.team, \n",
        "        args.start_year, \n",
        "        args.start_month, \n",
        "        args.end_year, \n",
        "        args.end_month,\n",
        "        args.session\n",
        "    )\n",
        "    \n",
        "    if not df.empty:\n",
        "        df.to_csv(args.output, index=False)\n",
        "        print(f\"Data saved to {args.output}\")\n",
        "    else:\n",
        "        print(\"No data was collected\")\n"
      ],
      "id": "3fdcbc37",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}