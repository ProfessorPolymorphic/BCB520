[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BCB 520:: Foundations of Data Visualization",
    "section": "",
    "text": "This class will help students establish a core understanding of data visualization. We will consider how data type (including tabular, network, and spatial data) interacts with visualization task to guide design choices. Diverse types of visual encodings and how they relate to human perception will be presented, along with practical exercises using the R and Python programming languages. Upon completion of the course, students will understand WHY particular visualization approaches are effective for a given data set and HOW to implement those visualizations using the language of their choice. The course is designed to be “discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests.\n\n\nI am maintaining the course here and on its CANVAS PAGE (for enrolled students).\nSYLLABUS\nBarrie’s GitHub\n\n\n\nGGSIDE! A companion to ggplot for making side plots! COOL!\nAwesome Quarto: A potentially interesting repository of Quarto documents, talks, tools, examples, etc.\nThe MockUp Blog - TABLES! This blog post explores the R packages gt and gtextras which will help us up our table game!\nRiffomonas Project: Pat Schloss is a Professor at the University of Michigan. The Riffomonas Project is his Youtube channel, which has HUNDREDS of easy to follow and amazingly useful instructional videos on R, ggplot, version control, and literate programming.\nDr. Tamara Munzner’s Website: It isn’t fancy, but Dr. Munzner’s website has tons of resources from her textbook and the many data visualization courses she has offered. This includes recorded lectures that align directly with the chapters of the text, much like what we are using.\nCheat Sheets: So many visual guides for many R packages, including the tidyverse, ggplot, dplyr, etc.\nLearning Vis Tools: Teaching Data Visualization Tutorials An interesting paper for discussion as we forge the structure for this class."
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "BCB 520:: Foundations of Data Visualization",
    "section": "",
    "text": "I am maintaining the course here and on its CANVAS PAGE (for enrolled students).\nSYLLABUS\nBarrie’s GitHub"
  },
  {
    "objectID": "index.html#learning-resources",
    "href": "index.html#learning-resources",
    "title": "BCB 520:: Foundations of Data Visualization",
    "section": "",
    "text": "GGSIDE! A companion to ggplot for making side plots! COOL!\nAwesome Quarto: A potentially interesting repository of Quarto documents, talks, tools, examples, etc.\nThe MockUp Blog - TABLES! This blog post explores the R packages gt and gtextras which will help us up our table game!\nRiffomonas Project: Pat Schloss is a Professor at the University of Michigan. The Riffomonas Project is his Youtube channel, which has HUNDREDS of easy to follow and amazingly useful instructional videos on R, ggplot, version control, and literate programming.\nDr. Tamara Munzner’s Website: It isn’t fancy, but Dr. Munzner’s website has tons of resources from her textbook and the many data visualization courses she has offered. This includes recorded lectures that align directly with the chapters of the text, much like what we are using.\nCheat Sheets: So many visual guides for many R packages, including the tidyverse, ggplot, dplyr, etc.\nLearning Vis Tools: Teaching Data Visualization Tutorials An interesting paper for discussion as we forge the structure for this class."
  },
  {
    "objectID": "posts/T1-Lit-Prog/index.html",
    "href": "posts/T1-Lit-Prog/index.html",
    "title": "TUTORIAL 1 - Literate Programming",
    "section": "",
    "text": "Learning new tools is hard. Plowing though the tomes of the Data Science Mythos is hard. Perhaps this tutorial will guide you through the mind shattering truths of… LITERATE PROGRAMMING."
  },
  {
    "objectID": "posts/T1-Lit-Prog/index.html#intro-to-quarto",
    "href": "posts/T1-Lit-Prog/index.html#intro-to-quarto",
    "title": "TUTORIAL 1 - Literate Programming",
    "section": "",
    "text": "Learning new tools is hard. Plowing though the tomes of the Data Science Mythos is hard. Perhaps this tutorial will guide you through the mind shattering truths of… LITERATE PROGRAMMING."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html",
    "href": "posts/A1-Lit-Prog/index.html",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "",
    "text": "The idea of Literate Programming is that source code that is executed as part of the program’s purpose is interspersed with documentation that describes the program’s logic. The concept of literate programming was first articulated by David Knuth in 1984. You know… back when music was good? Modern Data Science leans pretty heavily on literate programming, and to be honest, there aren’t very many good arguments as to why you WOULDN’T want to implement this approach in your own work. Bearing this in mind, we will adopt this framework for most of the activities, exercises, and assignments in this course. All of us will benefit by practicing these skills."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#summary",
    "href": "posts/A1-Lit-Prog/index.html#summary",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "",
    "text": "The idea of Literate Programming is that source code that is executed as part of the program’s purpose is interspersed with documentation that describes the program’s logic. The concept of literate programming was first articulated by David Knuth in 1984. You know… back when music was good? Modern Data Science leans pretty heavily on literate programming, and to be honest, there aren’t very many good arguments as to why you WOULDN’T want to implement this approach in your own work. Bearing this in mind, we will adopt this framework for most of the activities, exercises, and assignments in this course. All of us will benefit by practicing these skills."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "href": "posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LITERATE PROGRAMMING PUBLISHING SYSTEMS",
    "text": "LITERATE PROGRAMMING PUBLISHING SYSTEMS\nI’m trying to keep this course as technology agnostic as I can. The idea is that you should be practicing and building competencies in the languages and algorithms that are most useful to you. Who am I to tell you to use R instead of Python? If you have skills in a particular language I encourage you to keep using that during this course. That being said, I am going to work the examples using R and R Studio, and I will (mostly) use Quarto as the literate programming framework.\nIf all of this is new to you, no problem. Just follow along in R and Quarto and start your skill building journey with those languages.\nIf you are a Python person, great! Quarto can accommodate that language as well. If you have another preference for literate programming, such as sticking with R Markdown until the Quarto bugs are fixed, that is great. Find the framework and tools that work for you, and practice, practice, practice!\n\nQuarto\nAn open source publishing system that allows you to create websites, documents, blogs, books, publications, presentations, and more while using R, Python, Julia, or Observable. Quarto is intended to be the more functional successor of R Markdown. I intend to use Quarto for most of my work in this course.\n\n\nR Markdown\nAnother publishing system for creating all the things … websites, slides, manuscripts, dashboards, etc. While most people (including me!) instinctively think of R and Python within R Markdown, the list of supported language engines is pretty extensive.\n\nnames(knitr::knit_engines$get())\n\n [1] \"awk\"       \"bash\"      \"coffee\"    \"gawk\"      \"groovy\"    \"haskell\"  \n [7] \"lein\"      \"mysql\"     \"node\"      \"octave\"    \"perl\"      \"php\"      \n[13] \"psql\"      \"Rscript\"   \"ruby\"      \"sas\"       \"scala\"     \"sed\"      \n[19] \"sh\"        \"stata\"     \"zsh\"       \"asis\"      \"asy\"       \"block\"    \n[25] \"block2\"    \"bslib\"     \"c\"         \"cat\"       \"cc\"        \"comment\"  \n[31] \"css\"       \"ditaa\"     \"dot\"       \"embed\"     \"eviews\"    \"exec\"     \n[37] \"fortran\"   \"fortran95\" \"go\"        \"highlight\" \"js\"        \"julia\"    \n[43] \"python\"    \"R\"         \"Rcpp\"      \"sass\"      \"scss\"      \"sql\"      \n[49] \"stan\"      \"targets\"   \"tikz\"      \"verbatim\"  \"ojs\"       \"mermaid\""
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "href": "posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LANGUAGES AND TOOLSETS",
    "text": "LANGUAGES AND TOOLSETS\nThere are quite a few, but the five that seemed to keep coming up as I prepped this course are:\n\nR\nA very powerful open source framework for statistical computing and graphics. R has a lot of base functionality, and its capabilities are increased by 100 fold with packages created by R users. Packages are the core units of R code. I’m going to use R for the vast majority of demonstrations in this course.\n\n\nPython\nPython is an open source general purpose programming language. It wasn’t developed just for statistical computing or data science, and people use this language for tons of different applications. There is no denying it has become a very powerful language for data science and data visualization.\n\n\nTableau\nTableau is proprietary software that is very powerful for creating beautiful and functional data visualizations. It can integrate with all sorts of data sources and is used a lot for analytics, especially in the business world. The downsides (that occur to me at least) are that it costs money, it is not open source, and is more of a one-trick-pony than the programming languages on this list.\n\n\nJavascript\nJavascript has been around for about 25 years, and is (I think) the world’s most popular programming language. Along with HTML and CSS, Javascript drives pretty much the entire internet. I mention Javascript here because it has the D3 library, which can create super cool interactive data visualizaitons. In my experience, the learning curve with Javascript and D3 was pretty steep. I bought a book about it once, but just haven’t been able to allocate the amount of time necessary to really start using it. Check out the gallery of examples. Amazing!\n\n\nObservable / D3\nObservable is a set of extensions to Javascript that features something called reactive runtime. This means that the code blocks are executed and compiled as they are written, and changes are implemented instantaneously. Observable is pretty great for data exploration, and is well supported by Quarto. In addition, you can use the Observable JS libraries in Quarto to access D3. We’ll use some of these tools in this course, especially when we start considering interactivity."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#assignment",
    "href": "posts/A1-Lit-Prog/index.html#assignment",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nAfter that long introduction, I suppose you are wondering what I want you to actually DO today.\nWell, I want you to set up your publishing system and preferred language on your computer. Then I want you to recreate the classic figure from Anscombe’s Quartet.\nNow, you might be asking…\n“How am I supposed to do that? You haven’t taught me how to do anything yet!”\nHere is the dirty little secret of modern education.\nThe Internet Exists.\nWhile I could use up an entire 90 minute lecture telling you how to:\n\nDownload and install R, R-Studio, and Quarto (included by default with R-Studio).\nCreate a Quarto document that will publish in the .html format\nInstall the R packages you will need\nTidy up the Anscombe’s Quartet data\nCalculate the summary statistics for each x y pair\nMake a nice little plot…\n\nI’m not going to do that.\nInstead, I want you to use the resources I point towards, or other resources that make more sense to you, to figure out how to do those things."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#resources",
    "href": "posts/A1-Lit-Prog/index.html#resources",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "RESOURCES",
    "text": "RESOURCES\nTidyverse and Anscombe’s Quartet\nHandy cheat-sheets for many different R packages\nTutorial 1 - Literate Programming\nTutorial 2 - Literate Programming and Anscombe’s Quartet\nTutorial 3 - Python"
  },
  {
    "objectID": "posts/Certificate/index.html",
    "href": "posts/Certificate/index.html",
    "title": "CERTIFICATE",
    "section": "",
    "text": "Learn how to think about, organize, analyze, and visualize data. Communicate data-driven insights to technical and lay audiences."
  },
  {
    "objectID": "posts/Certificate/index.html#overview",
    "href": "posts/Certificate/index.html#overview",
    "title": "CERTIFICATE",
    "section": "OVERVIEW",
    "text": "OVERVIEW\nWe live in an increasingly data-driven world. Basic data literacy and data science skills are becoming central to virtually every industry. Yet, limited opportunities exist to gain these skills without an advanced background in math and computer science. To address this workforce development need, we propose a competitively valued on-line graduate certificate in the Professional Applications in Data Science. The certificate is designed to offer rigorous training in the foundations of data science to anyone with a bachelor’s degree. Participants will learn how to think about, organize, analyze, and visualize data, and communicate data driven insights to diverse audiences. The curriculum emphasizes the use of data sets drawn from each student’s individual discipline, aligning the certificate’s workforce development impacts with the University of Idaho’s land grant mission.\n\nValue Proposition:\nThe graduate certificate in Professional Applications in Data Science will provide unique value to UI constituencies by:\n\nAligning data science training with fields of nascent demand that are part of our land grant mission, including Agriculture, Natural Resources, and Education.\nRequiring a digital data science portfolio with which students can demonstrate their proficiencies to potential employers.\nEmphasizing training in data communication - including verbal presentation and data visualization - two components of data science that are underrepresented in competing certificates.\nFilling a growing workforce development gap by offering a unique data science certificate that is appropriate for professionals with a bachelor’s degree who do not have a rigorous background in mathematics, statistics, or computer science.\n\n\n\nIntended Audience:\nThis certificate leverages the University of Idaho’s interdisciplinary culture to provide integrative training in the foundations of data science. It is intended for:\n\nWorking professionals with a bachelor’s degree whose career increasingly involves the generation, management, analysis, and visualization of large data sets. The certificate is appropriate for professionals in STEM fields, Health Care, Business, Government, Education, Journalism, Athletics, Natural Resources, and Agriculture.\nGraduate students in programs outside of the core technical disciplines of data science (statistics, math, engineering, or computer science). The certificate will complement disciplinary research methods courses with training in data management, visualization, and communication.\nUndergraduates at the UI who wish to incorporate data science training into their degree and graduate with a Bachelor’s degree and a graduate certificate.\n\n\n\nStudent Learning Outcomes:\nUpon completion of the certificate, students will be able to:\n\nUse open-source software to reproducibly manage, analyze, and visualize large, complex, and noisy data sets.\nPractice high quality and ethical data stewardship.\nUnderstand and execute data exploration.\nEffectively communicate data driven insights to experts and non-experts.\nDemonstrate their skills with an online portfolio of analyses and visualizations relevant to their field of specialization."
  },
  {
    "objectID": "posts/Certificate/index.html#curriculum",
    "href": "posts/Certificate/index.html#curriculum",
    "title": "CERTIFICATE",
    "section": "CURRICULUM",
    "text": "CURRICULUM\n\nPrerequisites:\nA Bachelor’s degree OR the student has senior standing and is enrolled in a bachelor’s degree program at the University of Idaho.\n\n\nCertificate Requirements (12 Credits Total)\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\nSchedule\n\n\n\n\nINTR 509\nIntroduction to Applied Data Science\n3\nBS degree or permission\nSpring and asynchronous online\n\n\nBCB 551\nCommunicating with Data\n2\nINTR 509 or BS degree or permission\nFall and asynchronous online\n\n\nBCB 520\nData Visualization\n3\nSTAT 251 or INTR 509 or permission\nSpring and asynchronous online\n\n\nBCB 522\nData Science Portfolio\n1\nINTR 509 and BCB 520 (Data Viz)\nAsynchronous online\n\n\nElective\nVaries\n3\nVaries\nVaries\n\n\n\n\n\nnote: Courses designated with “BCB 5XX” are new courses that will be offered in the 2023-24 academic year\n\n\nCourse Descriptions\n\nINTR 509 Introduction to Applied Data Science (3 credits)\nIn person (spring) and asynchronous online.\nStudents are provided a foundation for “thinking with data” through the introduction of computational, statistical, and data literacy skills. This includes the selection, collection, cleaning, management, descriptive analysis, and exploratory analysis of a dataset unique to their professional interests using modern computing languages. This course is taught by Dr. Michael Overton.\n\n\nBCB 521 Communicating with Data (2 credits)\nIn person (fall) and asynchronous online.\nStudents are taught writing and presentation skills to improve their communication of data-driven insights to specialist and lay audiences. The course emphasizes reproducible research practices, including literate programming (R Markdown) and version control (GitHub). Course content includes the conceptual foundations of communicating with data along with written and verbal communication assignments using data sets individualized to each student’s interest.\nText: Nolan and Stoudt. 2021. Communicating with data: The art of writing for data science. Oxford University Press.\nPrerequisites: INTR 509 OR A BS degree OR permission.\n\n\nBCB 520 Data Visualization (3 credits)\nIn person (spring) and asynchronous online\nThis course covers the conceptual foundations of data visualization and design. Students will learn how visualization design choices related to marks and channels, color, and spatial arrangement interact with the human perceptual system. The course considers tabular, network, and spatial data, and students will implement visualizations in R.\nText: Munzner. 2014. Visualization Analysis & Design. CRC Press.\nPrerequisites: INTR 509 OR A BS degree OR Stat 251 OR Permission.\n\n\nBCB 522 Online Portfolio (1 credit)\nAsynchronous online\nThis course provides feedback, review, and approval of the student’s online data science portfolio. This portfolio is intended to represent the body of work accumulated by the student over the course of the certificate. It should contain examples of novel data products (such as FAIR data sets), analyses, and visualizations. All elements of the portfolio will be hosted online (likely in a GitHub repository or professional website), be open source, and demonstrate best practices of literate programming and reproducible research.\n\n\nElectives:\nThe certificate allows each student to customize their training by choosing a 3-credit graduate elective.\nFor students seeking foundational training who have not already taken Stat 431 or its equivalent, we recommend Stat 431 or a 3-credit graduate level disciplinary research methods course.\nFor students seeking to add the certificate to an existing degree at UI, or students who already have some advanced technical training, additional electives are possible. Note that many of these optional electives have substantial disciplinary pre-requisites. Not all electives are available in an online format.\n\n\nChoose one of the following:\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\n\n\n\n\nAVS 531\nPractical Methods in Analyzing Animal Science Experiments\n3\n400-level statistics course\n\n\nBE 521\nImage Processing and Computer Vision\n3\n(BE 242 and MATH 275) or permission\n\n\nBE 541\nInstrumentation and Measurements\n3\nENGR 240; Coreqs: STAT 301\n\n\nBIOL 526\nSystems Biology\n3\n(BIOL 115, BIOL 115L and MATH 170) or permission of instructor\n\n\nBIOL 545\nPhylogenetics\n3\nPLSC 205 or BIOL 213 and BIOL 310\n\n\nBIOL 549\nComputer Skills for Biologists\n3\nBIOL 310 and STAT 251 or STAT 301; or Permission\n\n\nBIOL 563\nMathematical Genetics\n3\nMATH 160 or MATH 170 and STAT 251 or STAT 301\n\n\nCE 526\nAquatic Habitat Modeling\n3\nA minimum grade of ‘C’ or better is required for all pre/corequisites; Prereqs: CE 322 and CE 325 or BE 355; or Permission\n\n\nCE 579\nSimulation of Transportation Systems\n3\nPermission\n\n\nCS 511\nParallel Programming\n3\nCS 395\n\n\nCS 574\nDeep Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 570\nArtificial Intelligence\n3\nCS 210\n\n\nCS 572\nEvolutionary Computation\n3\nCS 211\n\n\nCS 575\nMachine Learning\n3\nCS 210\n\n\nCS 577\nPython for Machine Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 578\nNeural Network Design\n3\nPermission\n\n\nCS 579\nData Science\n3\nMATH 330 or Permission\n\n\nCS 589\nSemantic Web and Open Data\n3\nCS 360 or CS 479 or CS 579\n\n\nCTE 519\nDatabase Applications and Information Management\n3\nNA\n\n\nCYB 520\nDigital Forensics\n3\nCYB 310\n\n\nED 571\nIntroduction to Quantitative Research\n3\nGraduate standing\n\n\nED 584\nUnivariate Quantitative Research in Education\n3\nED 571\n\n\nED 587\nMultivariate Quantitative Analysis in Education\n3\nED 584 or Permission\n\n\nED 589\nTheoretical Applications and Designs of Qualitative Research\n3\nED 574 or Permission\n\n\nED 590\nData Analysis and Interpretation of Qualitative Research\n3\nED 574 and ED 589\n\n\nED 591\nIndigenous and Decolonizing Research Methods\n3\nNA\n\n\nED 592\nDecolonizing, Indigenous, and Action-Based Research Methods\n3\nNA\n\n\nED 595\nSurvey Design for Social Science Research\n3\nRecommended Preparation: Foundations of Research course at graduate level.\n\n\nEDAD 570\nMethods of Educational Research\n3\nNA\n\n\nENT 504\nApplied Bioinformatics\n3\nPermission\n\n\nENVS 511\nData Wizardry in Environmental Sciences\n3\nSTAT 251\n\n\nENVS 551\nResearch Methods in the Environmental Social Sciences\n3\nOne course or experience in basic statistics or Instructor Permission\n\n\nFOR 514\nForest Biometrics\n3\nSTAT 431 or equivalent\n\n\nFOR 535\nRemote Sensing of Fire\n3\nFOR 375 or permission\n\n\nGEOG 507\nSpatial Statistics and Modeling\n3\nSTAT 431 or permission\n\n\nGEOG 583\nRemote Sensing/GIS Integration\n3\nCoreqs: GEOG 385 or equivalent.\n\n\nMath 538\nStochastic Models\n3\nMATH 451 or Permission\n\n\nMIS 555\nData Management for Big Data\n3\nNA\n\n\nNRS 578\nLidar and optical remote sensing analysis using open-source software\n3\nSTAT251 & WLF370 or STAT427 and NRS/FOR 472 or equivalent/instructor permission\n\n\nPOLS 558\nResearch Methods for Local Government and Community Administration\n3\nSTAT 251\n\n\nREM 507\nLandscape and Habitat Dynamics\n3\nPermission; Recommended Preparation: courses in ecology, statistics, and GIS.\n\n\nStat 431\nStatistical Analysis\n3\nSTAT 251 or STAT 301\n\n\nSTAT 514\nNonparametric Statistics\n3\nSTAT 431\n\n\nSTAT 516\nApplied Regression Modeling\n3\nSTAT 431\n\n\nStat 517\nStatistical Learning and Predictive Modeling\n3\nSTAT 431\n\n\nStat 519\nMultivariate Analysis\n3\nSTAT 431 or equivalent.\n\n\nSTAT 535\nIntroduction to Bayesian Statistics\n3\nSTAT 431\n\n\nSTAT 555\nStatistical Ecology\n3\nMATH 451 or Permission\n\n\nStat 565\nComputer Intensive Methods\n3\n STAT 451, STAT 452, MATH 330, and computer programming experience or Permission\n\n\nWLF 552\nEcological Modeling\n3\nMATH 175 and FOR 221 or Permission.\n\n\nWLF 555\nStatistical Ecology\n3\nMATH 451 or permission\n\n\nWR 552\nWater Economics and Policy\n3\nAGEC 301 or AGEC 302, or ECON 351 or ECON 352, or by permission"
  },
  {
    "objectID": "posts/Certificate/index.html#general-university-requirements",
    "href": "posts/Certificate/index.html#general-university-requirements",
    "title": "CERTIFICATE",
    "section": "GENERAL UNIVERSITY REQUIREMENTS",
    "text": "GENERAL UNIVERSITY REQUIREMENTS\nIn addition to the requirements specified in this document, the certificate would be subject to all UI Policies regarding Graduate Certificates."
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#last-lecture",
    "href": "posts/L3-TaskAbstraction/index.html#last-lecture",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "LAST LECTURE",
    "text": "LAST LECTURE\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#task-abstraction",
    "href": "posts/L3-TaskAbstraction/index.html#task-abstraction",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TASK ABSTRACTION",
    "text": "TASK ABSTRACTION\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#from-domain-to-abstraction",
    "href": "posts/L3-TaskAbstraction/index.html#from-domain-to-abstraction",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "FROM DOMAIN TO ABSTRACTION",
    "text": "FROM DOMAIN TO ABSTRACTION"
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#key-components-of-task-abstraction",
    "href": "posts/L3-TaskAbstraction/index.html#key-components-of-task-abstraction",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "KEY COMPONENTS OF TASK ABSTRACTION",
    "text": "KEY COMPONENTS OF TASK ABSTRACTION\n{action, target} pairs\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#actions-and-targets",
    "href": "posts/L3-TaskAbstraction/index.html#actions-and-targets",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS AND TARGETS",
    "text": "ACTIONS AND TARGETS"
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#actions---analyze",
    "href": "posts/L3-TaskAbstraction/index.html#actions---analyze",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS - Analyze",
    "text": "ACTIONS - Analyze\n\n\n\nConsume: Information has already been generated and stored as data.\n\nDiscover: new knowledge, test hypothesis, generate new hypothesis, verify\nPresent: communicate something specific and already understood\nEnjoy: casual encounters with visualization\n\nProduce: generate new material or information\n\nAnnotate: addition of graphical or text to existing visualization elements\nRecord: saves or captures visualization elements as persistent artifacts (screenshots, lists, parameter sets, annotations)\nDerive: produce new data based on existing data (aka transform)"
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#actions---search",
    "href": "posts/L3-TaskAbstraction/index.html#actions---search",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS - Search",
    "text": "ACTIONS - Search\n\n\n\nLookup: Location and target both known\n\nExample: Look up humans in the Tree of Life, knowing they are mammals.\n\nLocate: Location unknown and target known\n\nExample: Look up rabbits in the Tree of Life, not knowing they are lagomorphs.\n\nBrowse: Location known and target unknown\n\nExample: Find any clades within Mammalia that have only one species.\n\nExplore: Location unknown and target unknown\n\nExample: Searching for anomalies in time series data."
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#actions---query",
    "href": "posts/L3-TaskAbstraction/index.html#actions---query",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS - Query",
    "text": "ACTIONS - Query\n\n\n\nQuery: How much of the data matters to the task?\n\nIdentify: One (specific Item, individual, cell, etc)\nCompare: Some (multiple targets)\nSummarize: All (very common, aka Overview)"
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#targets---all-data",
    "href": "posts/L3-TaskAbstraction/index.html#targets---all-data",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TARGETS - All Data",
    "text": "TARGETS - All Data"
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#targets---attributes",
    "href": "posts/L3-TaskAbstraction/index.html#targets---attributes",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TARGETS - Attributes",
    "text": "TARGETS - Attributes"
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#targets---other-data",
    "href": "posts/L3-TaskAbstraction/index.html#targets---other-data",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TARGETS - Other Data",
    "text": "TARGETS - Other Data"
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#summary",
    "href": "posts/L3-TaskAbstraction/index.html#summary",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "SUMMARY",
    "text": "SUMMARY\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "posts/L3-TaskAbstraction/index.html#mandatory-fun",
    "href": "posts/L3-TaskAbstraction/index.html#mandatory-fun",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "MANDATORY FUN",
    "text": "MANDATORY FUN\nWe will do these until everyone has done at least one example.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "posts/T4-BarriesData/index.html",
    "href": "posts/T4-BarriesData/index.html",
    "title": "TUTORIAL 4",
    "section": "",
    "text": "In this assignment (detalied here), I will identify, import, describe, and host a data set that will be used throughout the remainder of the BCB 520 course for Data Visualizations.\n\n\nI’ve chosen a subset of a large dataset produced by our evolutionary video game, Project Hastur. We built Project Hastur to be an evolutionary video game, and we are bold in our assertions of that fact. But we haven’t really published any evidence that the evolutionary model works. This data set is the beginning of that exercise.\n\n\n\n\n\n\nNote\n\n\n\nPROJECT HASTUR creates a unique challenge by combining elements of 3D tower defense and real-time strategy with biological evolution. Fight against alien Proteans that evolve - using biologically accurate models of evolution - to overcome the player’s defenses.\nEach creature you will face has its own unique genome controlling its abilities, behaviors, and appearance. Those that make it the furthest and do the most damage to your defenses have the most offspring you will have to defeat in the next generation. The result? Evolution responds to the player’s strategy and makes every playthrough a unique experience.\nUse four upgradable turret classes, plus airstrikes and combat robots, to fight against the Protean invasion. Make strategic decisions about which turrets to build, when to upgrade them, and where to place them on the hex grid. A well-timed airstrike can change the flow of the game, but you’ll have to wait before you can use it again. Unlock powerful upgrades for each turret class as you move across the Nyx system. As you play, the Proteans evolve new weapon resistances, behaviors, and movement capabilities to better destroy your defenses.\nIn CAMPAIGN MODE, battle through a series of maps as a military defense commander to protect the planet Nyx from the ever-evolving threat of the Proteans. Unlock weapons and upgrades and use them to fight against the Protean swarm and learn about the mysteries of Project Hastur.\nIn EXPERIMENT MODE, choose any map, tweak the parameters, and play infinitely to see what you can evolve. Change the number of creatures and the parameters of evolution, make your turrets invincible, or crank up the biomatter and experiment with the most powerful turret upgrades. Experiment mode lets you experience Project Hastur your way.\n\n\n\n\nThe data were collected by running Project Hastur in Experiment mode using four predefined conditions:\nI: The CHIP SHREDDER towers when Fitness Functions were turned ON and Civilians were PRESENT.\nH: The CHIP SHREDDER towers when Fitness Functions were turned OFF and Civilians were PRESENT.\nG: The CHIP SHREDDER towers when Fitness Functions were turned ON and Civilians were ABSENT.\nK: The AUTOCANNON towers when Fitness Functions were turned ON and Civilians were ABSENT.\nEach experimental condition was run 9 times (9 replicates).\n\n\n\n\nI’m going to use the vroom package to import multiple files. Each file is a replicate and the filename tells us about the experimental condition. Below I convert the filename variable (I named it path) into a a single categorical attribute called Fit that uses the letter codes above.\n\n\nCode\nlibrary(vroom)\nlibrary(stringr)\nlibrary(tidyverse)\nlibrary(readxl)\nfiles &lt;- fs::dir_ls(glob = \"*.csv\")\n\nHastur &lt;- vroom(files, id = \"path\", \n                col_select = c(path, Generation, ID, Origin, AsexualReproduction, Fitness, Health,\n                               SightRange, Armor, Damage, WalkSpeed, RunSpeed, Acceleration, \n                               TurnRate, Attraction0, Attraction1, Attraction2))\n\nHastur$Fit &lt;- str_split_i(Hastur$path, pattern = \"\", 1)\nHastur$replicate &lt;- str_split_i(Hastur$path, pattern = \"\", 4)\n\n\nThe glimpse command in the Tidyverse package is a nice way to summarize the data frame:\n\n\nCode\nglimpse(Hastur)\n\n\nRows: 412,246\nColumns: 19\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n$ path                &lt;chr&gt; \"GSC1.csv\", \"GSC1.csv\", \"GSC1.csv\", \"GSC1.csv\", \"G…\n$ Generation          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ID                  &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ Origin              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ AsexualReproduction &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Fitness             &lt;dbl&gt; 57.83508, 66.87755, 66.14652, 65.88873, 62.12119, …\n$ Health              &lt;dbl&gt; 1006, 1012, 1011, 992, 983, 1020, 982, 963, 996, 9…\n$ SightRange          &lt;dbl&gt; 9.952521, 10.096590, 9.954091, 10.066170, 10.02955…\n$ Armor               &lt;dbl&gt; 0.05081077, 0.05080924, 0.05010696, 0.04903501, 0.…\n$ Damage              &lt;dbl&gt; 49, 51, 51, 50, 50, 51, 50, 49, 51, 50, 49, 50, 49…\n$ WalkSpeed           &lt;dbl&gt; 6.930266, 7.034348, 6.970608, 6.903729, 6.962081, …\n$ RunSpeed            &lt;dbl&gt; 20.03562, 19.88800, 19.80754, 19.94738, 19.95583, …\n$ Acceleration        &lt;dbl&gt; 14.70648, 15.05868, 14.85994, 14.89853, 15.01570, …\n$ TurnRate            &lt;dbl&gt; 356.3890, 361.2032, 358.9919, 361.8476, 360.6143, …\n$ Attraction0         &lt;dbl&gt; 0.158477500, -0.007134318, -0.063494000, 0.0125864…\n$ Attraction1         &lt;dbl&gt; -0.070695680, 0.059872570, -0.003332689, 0.0458469…\n$ Attraction2         &lt;dbl&gt; -0.108705200, 0.015018780, -0.007600136, 0.0120656…\n$ Fit                 &lt;chr&gt; \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", …\n$ replicate           &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", …\n\n\n\n\n\n\n\nWhat we have here is a (big) Flat Table. The Items are the rows, and each row is an individual alien enemy that existed during one of the replicates. Each Item (alien) is described by Attributes, which are arranged in the columns.\n\n\n\nThe glimpse we did in the preceding section gives us a hint as to what each attribute type might be. Let’s flesh that out a bit though. I’m going to create a new data frame that describes the attributes.\n\n\nCode\nAttributes &lt;- read_excel(\"Attributes.xlsx\")\nknitr::kable(Attributes)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nNote\n\n\n\n\npath\nCategorical\neach File Name is a unique replicate\n\n\nGeneration\nQuantitative\nEach Enemy Wave is a Generation\n\n\nID\nOrdinal\nEach enemy has a unique ID within each replicate\n\n\nOrigin\nCategorical\nThe hive from which the enemy was spawned\n\n\nAsexualReproduction\nCategorical\nWas the enemy spawned by infectiing a civilian?\n\n\nFitness\nQuantitative\nThe value of Fitness is used to determine probability of reproduction\n\n\nHealth\nQuantitative\nHit Points\n\n\nSightRange\nQuantitative\nHow far they can see civilians, towers, etc\n\n\nArmor\nQuantitative\nresistance to physical damage\n\n\nDamage\nQuantitative\nhow much damage they do to towers\n\n\nWalkSpeed\nQuantitative\nhow fast they can walk\n\n\nRunSpeed\nQuantitative\nhow fast they can run\n\n\nAcceleration\nQuantitative\nhow fast they can transition from walking to running\n\n\nTurnRate\nQuantitative\nhow fast they can turn\n\n\nAttraction0\nQuantitative\nnegative values is attraction to civilians, positive is avoidance\n\n\nAttraction1\nQuantitative\nnegative values is attraction to towers, positive is avoidance\n\n\nAttraction2\nQuantitative\nnegative values is attraction to the base, positive is avoidance\n\n\nFit\nCategorical\nI, H, G, or K - an inscrutable code about fitness conditions\n\n\n\n\n\nThe problem here is my inscrutable filename codes for that Fit variable. Those letter codes actually contain information on a couple hidden variables. I’m going to create a new variable called Gun and another called Civilians. I’ll add those to the main data file and also the Data Dicttionary.\n\n\nCode\nHastur$Gun &lt;- \"CHIP SHREDDER\"\nHastur$Civilians &lt;- \"Present\"\n  \n\n  Hastur$Gun[Hastur$Fit==\"K\"]&lt;- \"AUTOCANNON\"\n     \n  Hastur$Civilians[Hastur$Fit==\"K\" | Hastur$Fit ==\"G\"] &lt;- \"ABSENT\"\n     \n\n  Attributes&lt;-rbind(Attributes, c(\"Gun\",\"Categorical\", \"Autocannon or Chip Shredder\"))\n  Attributes&lt;-rbind(Attributes, c(\"Civilians\",\"Categorical\", \"Present or Absent\"))\n\n\n\n\nCode\n  knitr::kable(Attributes)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nNote\n\n\n\n\npath\nCategorical\neach File Name is a unique replicate\n\n\nGeneration\nQuantitative\nEach Enemy Wave is a Generation\n\n\nID\nOrdinal\nEach enemy has a unique ID within each replicate\n\n\nOrigin\nCategorical\nThe hive from which the enemy was spawned\n\n\nAsexualReproduction\nCategorical\nWas the enemy spawned by infectiing a civilian?\n\n\nFitness\nQuantitative\nThe value of Fitness is used to determine probability of reproduction\n\n\nHealth\nQuantitative\nHit Points\n\n\nSightRange\nQuantitative\nHow far they can see civilians, towers, etc\n\n\nArmor\nQuantitative\nresistance to physical damage\n\n\nDamage\nQuantitative\nhow much damage they do to towers\n\n\nWalkSpeed\nQuantitative\nhow fast they can walk\n\n\nRunSpeed\nQuantitative\nhow fast they can run\n\n\nAcceleration\nQuantitative\nhow fast they can transition from walking to running\n\n\nTurnRate\nQuantitative\nhow fast they can turn\n\n\nAttraction0\nQuantitative\nnegative values is attraction to civilians, positive is avoidance\n\n\nAttraction1\nQuantitative\nnegative values is attraction to towers, positive is avoidance\n\n\nAttraction2\nQuantitative\nnegative values is attraction to the base, positive is avoidance\n\n\nFit\nCategorical\nI, H, G, or K - an inscrutable code about fitness conditions\n\n\nGun\nCategorical\nAutocannon or Chip Shredder\n\n\nCivilians\nCategorical\nPresent or Absent\n\n\n\n\n\n\n\n\n\nI’m publishing to GitHub! We will elaborate on this step as everyone progresses through the assignment.\n\n\n\nFor this data set, I am currently defining the user as … me! My hypothesis is that the two Fitness conditions create different evolutionary outcomes of the aliens in Project Hastur. Some relevant ACTION TARGET pairs might be:\nDISCOVER TRENDS\nDISCOVER DISTRIBUTION\nDISCOVER SIMILARITY\nCOMPARE TRENDS\nCOMPARE DISTRIBUTION\nI’m going to try COMPARE TRENDS. I want to COMPARE the TREND in Health over time (Generation) between the two Gun types. To do this, I’ll create a scatterplot, faceted by Gun. I’m suspicious that Acceleration is involved somehow, so I’m coloring with that variable.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Health))+\n  geom_point(aes(color=Acceleration), alpha = 0.01, size = 1)+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_grid(replicate~Gun)\n\n\n\n\n\n\n\n\n\nInteresting… it looks like a clear trend for Health to increase under the withering fire of the AUTO CANNONS, but not when the player uses the CHIP SHREDDER. It is a bit hard to see what is going on with Acceleration, so let’s reverse the graphs so that we plot Acceleration on the y axis but color by Health.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Acceleration))+\n  geom_point(aes(color=Health), alpha = 0.01, size = 1)+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_grid(replicate~Gun)\n\n\n\n\n\n\n\n\n\nI’m now confident that the replicates within each Gun type are pretty similar, and I can SUMMARIZE the individual data points. This will help with the COMPARE TRENDS task, I think.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Health))+\n  geom_point(aes(color=Acceleration), alpha = 0.01, size = 1)+\n  geom_smooth()+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_wrap(~Gun)\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Acceleration))+\n  geom_point(aes(color=Health), alpha = 0.01, size = 1)+\n  geom_smooth()+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_wrap(~Gun)\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'"
  },
  {
    "objectID": "posts/T4-BarriesData/index.html#my-dataset",
    "href": "posts/T4-BarriesData/index.html#my-dataset",
    "title": "TUTORIAL 4",
    "section": "",
    "text": "I’ve chosen a subset of a large dataset produced by our evolutionary video game, Project Hastur. We built Project Hastur to be an evolutionary video game, and we are bold in our assertions of that fact. But we haven’t really published any evidence that the evolutionary model works. This data set is the beginning of that exercise.\n\n\n\n\n\n\nNote\n\n\n\nPROJECT HASTUR creates a unique challenge by combining elements of 3D tower defense and real-time strategy with biological evolution. Fight against alien Proteans that evolve - using biologically accurate models of evolution - to overcome the player’s defenses.\nEach creature you will face has its own unique genome controlling its abilities, behaviors, and appearance. Those that make it the furthest and do the most damage to your defenses have the most offspring you will have to defeat in the next generation. The result? Evolution responds to the player’s strategy and makes every playthrough a unique experience.\nUse four upgradable turret classes, plus airstrikes and combat robots, to fight against the Protean invasion. Make strategic decisions about which turrets to build, when to upgrade them, and where to place them on the hex grid. A well-timed airstrike can change the flow of the game, but you’ll have to wait before you can use it again. Unlock powerful upgrades for each turret class as you move across the Nyx system. As you play, the Proteans evolve new weapon resistances, behaviors, and movement capabilities to better destroy your defenses.\nIn CAMPAIGN MODE, battle through a series of maps as a military defense commander to protect the planet Nyx from the ever-evolving threat of the Proteans. Unlock weapons and upgrades and use them to fight against the Protean swarm and learn about the mysteries of Project Hastur.\nIn EXPERIMENT MODE, choose any map, tweak the parameters, and play infinitely to see what you can evolve. Change the number of creatures and the parameters of evolution, make your turrets invincible, or crank up the biomatter and experiment with the most powerful turret upgrades. Experiment mode lets you experience Project Hastur your way.\n\n\n\n\nThe data were collected by running Project Hastur in Experiment mode using four predefined conditions:\nI: The CHIP SHREDDER towers when Fitness Functions were turned ON and Civilians were PRESENT.\nH: The CHIP SHREDDER towers when Fitness Functions were turned OFF and Civilians were PRESENT.\nG: The CHIP SHREDDER towers when Fitness Functions were turned ON and Civilians were ABSENT.\nK: The AUTOCANNON towers when Fitness Functions were turned ON and Civilians were ABSENT.\nEach experimental condition was run 9 times (9 replicates)."
  },
  {
    "objectID": "posts/T4-BarriesData/index.html#importing-the-data",
    "href": "posts/T4-BarriesData/index.html#importing-the-data",
    "title": "TUTORIAL 4",
    "section": "",
    "text": "I’m going to use the vroom package to import multiple files. Each file is a replicate and the filename tells us about the experimental condition. Below I convert the filename variable (I named it path) into a a single categorical attribute called Fit that uses the letter codes above.\n\n\nCode\nlibrary(vroom)\nlibrary(stringr)\nlibrary(tidyverse)\nlibrary(readxl)\nfiles &lt;- fs::dir_ls(glob = \"*.csv\")\n\nHastur &lt;- vroom(files, id = \"path\", \n                col_select = c(path, Generation, ID, Origin, AsexualReproduction, Fitness, Health,\n                               SightRange, Armor, Damage, WalkSpeed, RunSpeed, Acceleration, \n                               TurnRate, Attraction0, Attraction1, Attraction2))\n\nHastur$Fit &lt;- str_split_i(Hastur$path, pattern = \"\", 1)\nHastur$replicate &lt;- str_split_i(Hastur$path, pattern = \"\", 4)\n\n\nThe glimpse command in the Tidyverse package is a nice way to summarize the data frame:\n\n\nCode\nglimpse(Hastur)\n\n\nRows: 412,246\nColumns: 19\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n$ path                &lt;chr&gt; \"GSC1.csv\", \"GSC1.csv\", \"GSC1.csv\", \"GSC1.csv\", \"G…\n$ Generation          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ID                  &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ Origin              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ AsexualReproduction &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Fitness             &lt;dbl&gt; 57.83508, 66.87755, 66.14652, 65.88873, 62.12119, …\n$ Health              &lt;dbl&gt; 1006, 1012, 1011, 992, 983, 1020, 982, 963, 996, 9…\n$ SightRange          &lt;dbl&gt; 9.952521, 10.096590, 9.954091, 10.066170, 10.02955…\n$ Armor               &lt;dbl&gt; 0.05081077, 0.05080924, 0.05010696, 0.04903501, 0.…\n$ Damage              &lt;dbl&gt; 49, 51, 51, 50, 50, 51, 50, 49, 51, 50, 49, 50, 49…\n$ WalkSpeed           &lt;dbl&gt; 6.930266, 7.034348, 6.970608, 6.903729, 6.962081, …\n$ RunSpeed            &lt;dbl&gt; 20.03562, 19.88800, 19.80754, 19.94738, 19.95583, …\n$ Acceleration        &lt;dbl&gt; 14.70648, 15.05868, 14.85994, 14.89853, 15.01570, …\n$ TurnRate            &lt;dbl&gt; 356.3890, 361.2032, 358.9919, 361.8476, 360.6143, …\n$ Attraction0         &lt;dbl&gt; 0.158477500, -0.007134318, -0.063494000, 0.0125864…\n$ Attraction1         &lt;dbl&gt; -0.070695680, 0.059872570, -0.003332689, 0.0458469…\n$ Attraction2         &lt;dbl&gt; -0.108705200, 0.015018780, -0.007600136, 0.0120656…\n$ Fit                 &lt;chr&gt; \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", …\n$ replicate           &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", …"
  },
  {
    "objectID": "posts/T4-BarriesData/index.html#describe-the-data",
    "href": "posts/T4-BarriesData/index.html#describe-the-data",
    "title": "TUTORIAL 4",
    "section": "",
    "text": "What we have here is a (big) Flat Table. The Items are the rows, and each row is an individual alien enemy that existed during one of the replicates. Each Item (alien) is described by Attributes, which are arranged in the columns.\n\n\n\nThe glimpse we did in the preceding section gives us a hint as to what each attribute type might be. Let’s flesh that out a bit though. I’m going to create a new data frame that describes the attributes.\n\n\nCode\nAttributes &lt;- read_excel(\"Attributes.xlsx\")\nknitr::kable(Attributes)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nNote\n\n\n\n\npath\nCategorical\neach File Name is a unique replicate\n\n\nGeneration\nQuantitative\nEach Enemy Wave is a Generation\n\n\nID\nOrdinal\nEach enemy has a unique ID within each replicate\n\n\nOrigin\nCategorical\nThe hive from which the enemy was spawned\n\n\nAsexualReproduction\nCategorical\nWas the enemy spawned by infectiing a civilian?\n\n\nFitness\nQuantitative\nThe value of Fitness is used to determine probability of reproduction\n\n\nHealth\nQuantitative\nHit Points\n\n\nSightRange\nQuantitative\nHow far they can see civilians, towers, etc\n\n\nArmor\nQuantitative\nresistance to physical damage\n\n\nDamage\nQuantitative\nhow much damage they do to towers\n\n\nWalkSpeed\nQuantitative\nhow fast they can walk\n\n\nRunSpeed\nQuantitative\nhow fast they can run\n\n\nAcceleration\nQuantitative\nhow fast they can transition from walking to running\n\n\nTurnRate\nQuantitative\nhow fast they can turn\n\n\nAttraction0\nQuantitative\nnegative values is attraction to civilians, positive is avoidance\n\n\nAttraction1\nQuantitative\nnegative values is attraction to towers, positive is avoidance\n\n\nAttraction2\nQuantitative\nnegative values is attraction to the base, positive is avoidance\n\n\nFit\nCategorical\nI, H, G, or K - an inscrutable code about fitness conditions\n\n\n\n\n\nThe problem here is my inscrutable filename codes for that Fit variable. Those letter codes actually contain information on a couple hidden variables. I’m going to create a new variable called Gun and another called Civilians. I’ll add those to the main data file and also the Data Dicttionary.\n\n\nCode\nHastur$Gun &lt;- \"CHIP SHREDDER\"\nHastur$Civilians &lt;- \"Present\"\n  \n\n  Hastur$Gun[Hastur$Fit==\"K\"]&lt;- \"AUTOCANNON\"\n     \n  Hastur$Civilians[Hastur$Fit==\"K\" | Hastur$Fit ==\"G\"] &lt;- \"ABSENT\"\n     \n\n  Attributes&lt;-rbind(Attributes, c(\"Gun\",\"Categorical\", \"Autocannon or Chip Shredder\"))\n  Attributes&lt;-rbind(Attributes, c(\"Civilians\",\"Categorical\", \"Present or Absent\"))\n\n\n\n\nCode\n  knitr::kable(Attributes)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nNote\n\n\n\n\npath\nCategorical\neach File Name is a unique replicate\n\n\nGeneration\nQuantitative\nEach Enemy Wave is a Generation\n\n\nID\nOrdinal\nEach enemy has a unique ID within each replicate\n\n\nOrigin\nCategorical\nThe hive from which the enemy was spawned\n\n\nAsexualReproduction\nCategorical\nWas the enemy spawned by infectiing a civilian?\n\n\nFitness\nQuantitative\nThe value of Fitness is used to determine probability of reproduction\n\n\nHealth\nQuantitative\nHit Points\n\n\nSightRange\nQuantitative\nHow far they can see civilians, towers, etc\n\n\nArmor\nQuantitative\nresistance to physical damage\n\n\nDamage\nQuantitative\nhow much damage they do to towers\n\n\nWalkSpeed\nQuantitative\nhow fast they can walk\n\n\nRunSpeed\nQuantitative\nhow fast they can run\n\n\nAcceleration\nQuantitative\nhow fast they can transition from walking to running\n\n\nTurnRate\nQuantitative\nhow fast they can turn\n\n\nAttraction0\nQuantitative\nnegative values is attraction to civilians, positive is avoidance\n\n\nAttraction1\nQuantitative\nnegative values is attraction to towers, positive is avoidance\n\n\nAttraction2\nQuantitative\nnegative values is attraction to the base, positive is avoidance\n\n\nFit\nCategorical\nI, H, G, or K - an inscrutable code about fitness conditions\n\n\nGun\nCategorical\nAutocannon or Chip Shredder\n\n\nCivilians\nCategorical\nPresent or Absent"
  },
  {
    "objectID": "posts/T4-BarriesData/index.html#host-the-data",
    "href": "posts/T4-BarriesData/index.html#host-the-data",
    "title": "TUTORIAL 4",
    "section": "",
    "text": "I’m publishing to GitHub! We will elaborate on this step as everyone progresses through the assignment."
  },
  {
    "objectID": "posts/T4-BarriesData/index.html#task-abstraction",
    "href": "posts/T4-BarriesData/index.html#task-abstraction",
    "title": "TUTORIAL 4",
    "section": "",
    "text": "For this data set, I am currently defining the user as … me! My hypothesis is that the two Fitness conditions create different evolutionary outcomes of the aliens in Project Hastur. Some relevant ACTION TARGET pairs might be:\nDISCOVER TRENDS\nDISCOVER DISTRIBUTION\nDISCOVER SIMILARITY\nCOMPARE TRENDS\nCOMPARE DISTRIBUTION\nI’m going to try COMPARE TRENDS. I want to COMPARE the TREND in Health over time (Generation) between the two Gun types. To do this, I’ll create a scatterplot, faceted by Gun. I’m suspicious that Acceleration is involved somehow, so I’m coloring with that variable.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Health))+\n  geom_point(aes(color=Acceleration), alpha = 0.01, size = 1)+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_grid(replicate~Gun)\n\n\n\n\n\n\n\n\n\nInteresting… it looks like a clear trend for Health to increase under the withering fire of the AUTO CANNONS, but not when the player uses the CHIP SHREDDER. It is a bit hard to see what is going on with Acceleration, so let’s reverse the graphs so that we plot Acceleration on the y axis but color by Health.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Acceleration))+\n  geom_point(aes(color=Health), alpha = 0.01, size = 1)+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_grid(replicate~Gun)\n\n\n\n\n\n\n\n\n\nI’m now confident that the replicates within each Gun type are pretty similar, and I can SUMMARIZE the individual data points. This will help with the COMPARE TRENDS task, I think.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Health))+\n  geom_point(aes(color=Acceleration), alpha = 0.01, size = 1)+\n  geom_smooth()+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_wrap(~Gun)\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Acceleration))+\n  geom_point(aes(color=Health), alpha = 0.01, size = 1)+\n  geom_smooth()+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_wrap(~Gun)\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#vad-model",
    "href": "posts/L4-Marks-Channels/index.html#vad-model",
    "title": "LECTURE 4",
    "section": "VAD MODEL",
    "text": "VAD MODEL"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#understand-the-data",
    "href": "posts/L4-Marks-Channels/index.html#understand-the-data",
    "title": "LECTURE 4",
    "section": "UNDERSTAND THE DATA",
    "text": "UNDERSTAND THE DATA\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#understand-the-task",
    "href": "posts/L4-Marks-Channels/index.html#understand-the-task",
    "title": "LECTURE 4",
    "section": "UNDERSTAND THE TASK",
    "text": "UNDERSTAND THE TASK\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#visual-encoding",
    "href": "posts/L4-Marks-Channels/index.html#visual-encoding",
    "title": "LECTURE 4",
    "section": "VISUAL ENCODING",
    "text": "VISUAL ENCODING\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#other-frameworks",
    "href": "posts/L4-Marks-Channels/index.html#other-frameworks",
    "title": "LECTURE 4",
    "section": "OTHER FRAMEWORKS",
    "text": "OTHER FRAMEWORKS\n\nThe Tidyverse\nThe Grammar of Graphics\nTufte"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#tidyverse",
    "href": "posts/L4-Marks-Channels/index.html#tidyverse",
    "title": "LECTURE 4",
    "section": "TIDYVERSE",
    "text": "TIDYVERSE\nR packages for data science:\n\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. The best way to explore and understand the tidyverse is with cheetsheets, like this one for tidyr!"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#grammar-of-graphics",
    "href": "posts/L4-Marks-Channels/index.html#grammar-of-graphics",
    "title": "LECTURE 4",
    "section": "GRAMMAR OF GRAPHICS",
    "text": "GRAMMAR OF GRAPHICS\nThe ggplot2 cheatsheet!"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#tufte",
    "href": "posts/L4-Marks-Channels/index.html#tufte",
    "title": "LECTURE 4",
    "section": "TUFTE",
    "text": "TUFTE\nTufte’s Website\nA Quarto Page Layout Example"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#analysis-framework",
    "href": "posts/L4-Marks-Channels/index.html#analysis-framework",
    "title": "LECTURE 4",
    "section": "ANALYSIS FRAMEWORK",
    "text": "ANALYSIS FRAMEWORK\nFour levels, three questions\n\n\n\nDomain situation defines the target users.\nAbstraction translate from specifics of domain to vocabulary of vis\n\nWHAT is shown? data abstraction\nWHY is the user looking at it? task abstraction\n\nIdiom defines the visualization\n\nHOW is it shown?\n\nvisual encoding idiom: how to draw\ninteraction idiom: how to manipulate\n\n\nAlgorithm creates the visualization\n\nevaluated with computational efficiency"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#encoding",
    "href": "posts/L4-Marks-Channels/index.html#encoding",
    "title": "LECTURE 4",
    "section": "ENCODING",
    "text": "ENCODING\nWe are defining the structure of the visualization (the idiom).\nTo do this, we use MARKS and CHANNELS:\n\nMARKS represent ITEMS or LINKS (aka OBSERVATIONS)\nCHANNELS change the appearance of MARKS based on ATTRIBUTES (aka VARIABLES)"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#marks-for-items",
    "href": "posts/L4-Marks-Channels/index.html#marks-for-items",
    "title": "LECTURE 4",
    "section": "MARKS FOR ITEMS",
    "text": "MARKS FOR ITEMS"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#marks-for-links",
    "href": "posts/L4-Marks-Channels/index.html#marks-for-links",
    "title": "LECTURE 4",
    "section": "MARKS FOR LINKS",
    "text": "MARKS FOR LINKS\n\n Bubblesets\n Force Directed Graph"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#observable-in-quarto",
    "href": "posts/L4-Marks-Channels/index.html#observable-in-quarto",
    "title": "LECTURE 4",
    "section": "OBSERVABLE IN QUARTO!",
    "text": "OBSERVABLE IN QUARTO!\n\n\nCode\nd3 = require(\"d3@7\")\n\n\nchart = ForceGraph(miserables, {\n  nodeId: d =&gt; d.id,\n  nodeGroup: d =&gt; d.group,\n  nodeTitle: d =&gt; `${d.id}\\n${d.group}`,\n  linkStrokeWidth: l =&gt; Math.sqrt(l.value),\n  width,\n  height: 1000,\n  invalidation // a promise to stop the simulation when the cell is re-run\n})\n\n\nmiserables = FileAttachment(\"miserables.json\").json()\n\n\n// Copyright 2021 Observable, Inc.\n// Released under the ISC license.\n// https://observablehq.com/@d3/force-directed-graph\nfunction ForceGraph({\n  nodes, // an iterable of node objects (typically [{id}, …])\n  links // an iterable of link objects (typically [{source, target}, …])\n}, {\n  nodeId = d =&gt; d.id, // given d in nodes, returns a unique identifier (string)\n  nodeGroup, // given d in nodes, returns an (ordinal) value for color\n  nodeGroups, // an array of ordinal values representing the node groups\n  nodeTitle, // given d in nodes, a title string\n  nodeFill = \"currentColor\", // node stroke fill (if not using a group color encoding)\n  nodeStroke = \"#fff\", // node stroke color\n  nodeStrokeWidth = 1.5, // node stroke width, in pixels\n  nodeStrokeOpacity = 1, // node stroke opacity\n  nodeRadius = 5, // node radius, in pixels\n  nodeStrength,\n  linkSource = ({source}) =&gt; source, // given d in links, returns a node identifier string\n  linkTarget = ({target}) =&gt; target, // given d in links, returns a node identifier string\n  linkStroke = \"#999\", // link stroke color\n  linkStrokeOpacity = 0.6, // link stroke opacity\n  linkStrokeWidth = 1.5, // given d in links, returns a stroke width in pixels\n  linkStrokeLinecap = \"round\", // link stroke linecap\n  linkStrength,\n  colors = d3.schemeTableau10, // an array of color strings, for the node groups\n  width = 1000, // outer width, in pixels\n  height = 1000, // outer height, in pixels\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  // Compute values.\n  const N = d3.map(nodes, nodeId).map(intern);\n  const LS = d3.map(links, linkSource).map(intern);\n  const LT = d3.map(links, linkTarget).map(intern);\n  if (nodeTitle === undefined) nodeTitle = (_, i) =&gt; N[i];\n  const T = nodeTitle == null ? null : d3.map(nodes, nodeTitle);\n  const G = nodeGroup == null ? null : d3.map(nodes, nodeGroup).map(intern);\n  const W = typeof linkStrokeWidth !== \"function\" ? null : d3.map(links, linkStrokeWidth);\n  const L = typeof linkStroke !== \"function\" ? null : d3.map(links, linkStroke);\n\n  // Replace the input nodes and links with mutable objects for the simulation.\n  nodes = d3.map(nodes, (_, i) =&gt; ({id: N[i]}));\n  links = d3.map(links, (_, i) =&gt; ({source: LS[i], target: LT[i]}));\n\n  // Compute default domains.\n  if (G && nodeGroups === undefined) nodeGroups = d3.sort(G);\n\n  // Construct the scales.\n  const color = nodeGroup == null ? null : d3.scaleOrdinal(nodeGroups, colors);\n\n  // Construct the forces.\n  const forceNode = d3.forceManyBody();\n  const forceLink = d3.forceLink(links).id(({index: i}) =&gt; N[i]);\n  if (nodeStrength !== undefined) forceNode.strength(nodeStrength);\n  if (linkStrength !== undefined) forceLink.strength(linkStrength);\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", forceLink)\n      .force(\"charge\", forceNode)\n      .force(\"center\",  d3.forceCenter())\n      .on(\"tick\", ticked);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height])\n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke\", typeof linkStroke !== \"function\" ? linkStroke : null)\n      .attr(\"stroke-opacity\", linkStrokeOpacity)\n      .attr(\"stroke-width\", typeof linkStrokeWidth !== \"function\" ? linkStrokeWidth : null)\n      .attr(\"stroke-linecap\", linkStrokeLinecap)\n    .selectAll(\"line\")\n    .data(links)\n    .join(\"line\");\n\n  const node = svg.append(\"g\")\n      .attr(\"fill\", nodeFill)\n      .attr(\"stroke\", nodeStroke)\n      .attr(\"stroke-opacity\", nodeStrokeOpacity)\n      .attr(\"stroke-width\", nodeStrokeWidth)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", nodeRadius)\n      .call(drag(simulation));\n\n  if (W) link.attr(\"stroke-width\", ({index: i}) =&gt; W[i]);\n  if (L) link.attr(\"stroke\", ({index: i}) =&gt; L[i]);\n  if (G) node.attr(\"fill\", ({index: i}) =&gt; color(G[i]));\n  if (T) node.append(\"title\").text(({index: i}) =&gt; T[i]);\n  if (invalidation != null) invalidation.then(() =&gt; simulation.stop());\n\n  function intern(value) {\n    return value !== null && typeof value === \"object\" ? value.valueOf() : value;\n  }\n\n  function ticked() {\n    link\n      .attr(\"x1\", d =&gt; d.source.x)\n      .attr(\"y1\", d =&gt; d.source.y)\n      .attr(\"x2\", d =&gt; d.target.x)\n      .attr(\"y2\", d =&gt; d.target.y);\n\n    node\n      .attr(\"cx\", d =&gt; d.x)\n      .attr(\"cy\", d =&gt; d.y);\n  }\n\n  function drag(simulation) {    \n    function dragstarted(event) {\n      if (!event.active) simulation.alphaTarget(0.3).restart();\n      event.subject.fx = event.subject.x;\n      event.subject.fy = event.subject.y;\n    }\n    \n    function dragged(event) {\n      event.subject.fx = event.x;\n      event.subject.fy = event.y;\n    }\n    \n    function dragended(event) {\n      if (!event.active) simulation.alphaTarget(0);\n      event.subject.fx = null;\n      event.subject.fy = null;\n    }\n    \n    return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n  }\n\n  return Object.assign(svg.node(), {scales: {color}});\n}\n\n\nimport {howto} from \"@d3/example-components\"\n\nimport {Swatches} from \"@d3/color-legend\""
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#channels",
    "href": "posts/L4-Marks-Channels/index.html#channels",
    "title": "LECTURE 4",
    "section": "CHANNELS",
    "text": "CHANNELS\n\n\n\nCHANNELS control the appearance of MARKS.\nThey are proportional to or based on ATTRIBUTES (aka VARIABLES).\nTheir properties differ in the type and amount of information that can be conveyed to the human perceptual system."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#visual-encoding-example",
    "href": "posts/L4-Marks-Channels/index.html#visual-encoding-example",
    "title": "LECTURE 4",
    "section": "VISUAL ENCODING EXAMPLE",
    "text": "VISUAL ENCODING EXAMPLE\nLet’s analyze the idiom structures below in terms of marks and channels."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#redundant-encoding",
    "href": "posts/L4-Marks-Channels/index.html#redundant-encoding",
    "title": "LECTURE 4",
    "section": "REDUNDANT ENCODING",
    "text": "REDUNDANT ENCODING\nUses multiple channels for the same attribute.\n\nSends a stronger message\nUses up channels\n\n ## WHEAT GROWTH BY AREA*"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#choosing-channels",
    "href": "posts/L4-Marks-Channels/index.html#choosing-channels",
    "title": "LECTURE 4",
    "section": "CHOOSING CHANNELS",
    "text": "CHOOSING CHANNELS\n\nEXPRESSIVENESS\n\nThe visual encoding should express all of, and only, the information in the dataset attributes.\n\nEFFECTIVENESS\n\nChannels differ in accuracy of perception.\nThe importance of the attribute should match the salience of the channel (its noticability)."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#channel-rankings",
    "href": "posts/L4-Marks-Channels/index.html#channel-rankings",
    "title": "LECTURE 4",
    "section": "CHANNEL RANKINGS",
    "text": "CHANNEL RANKINGS\n\nNote that spatial position ranks high for both types of channels."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#grouping",
    "href": "posts/L4-Marks-Channels/index.html#grouping",
    "title": "LECTURE 4",
    "section": "GROUPING",
    "text": "GROUPING\n\n\n\nContainment\nConnection\nProximity\n\nSame spatial region.\n\nSimilarity\n\nSame values as other channels."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#summary-so-far",
    "href": "posts/L4-Marks-Channels/index.html#summary-so-far",
    "title": "LECTURE 4",
    "section": "SUMMARY SO FAR",
    "text": "SUMMARY SO FAR"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#channel-effectiveness",
    "href": "posts/L4-Marks-Channels/index.html#channel-effectiveness",
    "title": "LECTURE 4",
    "section": "CHANNEL EFFECTIVENESS",
    "text": "CHANNEL EFFECTIVENESS\n\nAccuracy: how precisely can we tell the difference between encoded items?\nDiscriminability: how many unique steps can we perceive?\nSeparability: is our ability to use this channel affected by another one?\nPopout: can things jump out using this channel?"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#accuracy-theory",
    "href": "posts/L4-Marks-Channels/index.html#accuracy-theory",
    "title": "LECTURE 4",
    "section": "ACCURACY (THEORY)",
    "text": "ACCURACY (THEORY)\nSteven’s Psychophisical Power Law: \\(S=I^N\\)\n\n\n\n\n\n\n\n\n\n\n\n\nLENGTH (N=1)\nELECTRIC SHOCK (N=3.5)\nSATURATION (N=1.7)\nAREA (N=0.7)\nBRIGHTNESS (N=0.5)"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#accuracy-experimental",
    "href": "posts/L4-Marks-Channels/index.html#accuracy-experimental",
    "title": "LECTURE 4",
    "section": "ACCURACY (EXPERIMENTAL)",
    "text": "ACCURACY (EXPERIMENTAL)\n\n\n\n\n[Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods]"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#discriminability",
    "href": "posts/L4-Marks-Channels/index.html#discriminability",
    "title": "LECTURE 4",
    "section": "DISCRIMINABILITY",
    "text": "DISCRIMINABILITY\nHow many usable steps are in the channel? Are the differences between items perceptible to the human as intended?"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#separability-vs-integrality",
    "href": "posts/L4-Marks-Channels/index.html#separability-vs-integrality",
    "title": "LECTURE 4",
    "section": "SEPARABILITY VS INTEGRALITY",
    "text": "SEPARABILITY VS INTEGRALITY\nSeparable channels are orthogonal and independent. Integral channels are inextricably combined. Attempts to encode different information with integral channels creates Interference.\n\n\nFigure 5.10. Pairs of visual channels fall along a continuum from fully separable to intrinsically integral. Color and location are separable channels well suited to encode different data attributes for two different groupings that can be selectively attended to. However, size interacts with hue, which is harder to perceive for small objects. The horizontal size and and vertical size channels are automatically fused into an integrated perception of area, yielding three groups. Attempts to code separate information along the red and green axes of the RGB color space fail, because we simply perceive four different hues."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#popout",
    "href": "posts/L4-Marks-Channels/index.html#popout",
    "title": "LECTURE 4",
    "section": "POPOUT",
    "text": "POPOUT\nVISUAL POPOUT is often called preattentive processing or tunable detection.\n\n\nfind the red dot! How long does it take?\nPopout results from our low-level visual system performing massively parallel processing on certain visual channels, eliminating the need for the viewer to consciously direct attention to items one by one (serial search).\n\nFigure 5.11. Visual popout. (a) The red circle pops out from a small set of blue circles. (b) The red circle pops out from a large set of blue circles just as quickly. (c) The red circle also pops out from a small set of square shapes, although a bit slower than with color. (d) The red circle also pops out of a large set of red squares. (e) The red circle does not take long to find from a small set of mixed shapes and colors. (f) The red circle does not pop out from a large set of red squares and blue circles, and it can only be found by searching one by one through all the objects."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#popout-1",
    "href": "posts/L4-Marks-Channels/index.html#popout-1",
    "title": "LECTURE 4",
    "section": "POPOUT",
    "text": "POPOUT\n\n\nMany channels are compatible with preattentive processing and facilitate popout:\n\ntilt\nsize\nshape\nproximity\nshadow direction\n\nBut not all!\n\nExample: parallel line pairs do not pop out from tilted pairs."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#relative-vs-absolute-judgements",
    "href": "posts/L4-Marks-Channels/index.html#relative-vs-absolute-judgements",
    "title": "LECTURE 4",
    "section": "RELATIVE VS ABSOLUTE JUDGEMENTS",
    "text": "RELATIVE VS ABSOLUTE JUDGEMENTS\nThe human perceptual system is fundamentally based on relative judgements, not absolute ones. This is why accuracy increases with common frame/scale and alignment.\nWeber’s Law: The detectable difference in stimulus intensity \\(I\\) as a fixed percentage \\(K\\) of the object magnitude: \\(dI/I=K\\) .\n\nThe filled rectangles differ in length by 1:9, and it is therefore difficult to detect the difference without aligment. The white rectangles differ in length by 1:2, it is easier to see this difference even when the objects are unaligned."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#relative-luminance-judgements",
    "href": "posts/L4-Marks-Channels/index.html#relative-luminance-judgements",
    "title": "LECTURE 4",
    "section": "RELATIVE LUMINANCE JUDGEMENTS",
    "text": "RELATIVE LUMINANCE JUDGEMENTS\nHuman perception of luminance is completely contextual, and is based on contrast with surrounding colors."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#relative-color-judgements",
    "href": "posts/L4-Marks-Channels/index.html#relative-color-judgements",
    "title": "LECTURE 4",
    "section": "RELATIVE COLOR JUDGEMENTS",
    "text": "RELATIVE COLOR JUDGEMENTS\nOur visual system evolved to provide color constancy so that the same surface is identifiable across a broad set of illumination conditions, even though a physical light meter would yield very different readings. While the visual system works very well in natural environments, many of its mechanisms work against simple approaches to visually encoding information with color.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.15 shows two colorful cubes. In Figure 5.15(a) corresponding squares both appear to be red. In Figure 5.15(b), masks show that the tile color in the image apparently illuminated by a yellowish light source is actually orange, and for the bluish light the tiles are actually purple.\n\n\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#this-is-important",
    "href": "posts/L4-Marks-Channels/index.html#this-is-important",
    "title": "LECTURE 4",
    "section": "THIS IS IMPORTANT",
    "text": "THIS IS IMPORTANT\nChannel properties differ in the type and amount of information that can be conveyed to the human perceptual system."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#douglas-fir-growth",
    "href": "posts/L4-Marks-Channels/index.html#douglas-fir-growth",
    "title": "LECTURE 4",
    "section": "DOUGLAS FIR GROWTH",
    "text": "DOUGLAS FIR GROWTH"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#expressiveness",
    "href": "posts/L4-Marks-Channels/index.html#expressiveness",
    "title": "LECTURE 4",
    "section": "EXPRESSIVENESS",
    "text": "EXPRESSIVENESS\n\nThe advantages and disadvantages of jitter plots."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#channel-effectiveness-rankings",
    "href": "posts/L4-Marks-Channels/index.html#channel-effectiveness-rankings",
    "title": "LECTURE 4",
    "section": "CHANNEL EFFECTIVENESS RANKINGS",
    "text": "CHANNEL EFFECTIVENESS RANKINGS\n\nNote that spatial position ranks high for both types of channels."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#accuracy",
    "href": "posts/L4-Marks-Channels/index.html#accuracy",
    "title": "LECTURE 4",
    "section": "ACCURACY?",
    "text": "ACCURACY?\nDepends on the task. Which genre has the most game titles? Which genres are the top 4 in terms of game titles? Are there more Puzzle games than Strategy games?"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#discriminability-and-colors",
    "href": "posts/L4-Marks-Channels/index.html#discriminability-and-colors",
    "title": "LECTURE 4",
    "section": "DISCRIMINABILITY and COLORS",
    "text": "DISCRIMINABILITY and COLORS"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#separability",
    "href": "posts/L4-Marks-Channels/index.html#separability",
    "title": "LECTURE 4",
    "section": "SEPARABILITY",
    "text": "SEPARABILITY\n\nRedundancy may be desirable, but area interferes with hue, with larger shapes having more visual salience."
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#popout-goes-the-weevil",
    "href": "posts/L4-Marks-Channels/index.html#popout-goes-the-weevil",
    "title": "LECTURE 4",
    "section": "POPOUT GOES THE WEEVIL?",
    "text": "POPOUT GOES THE WEEVIL?"
  },
  {
    "objectID": "posts/L4-Marks-Channels/index.html#relative-judgements",
    "href": "posts/L4-Marks-Channels/index.html#relative-judgements",
    "title": "LECTURE 4",
    "section": "RELATIVE JUDGEMENTS",
    "text": "RELATIVE JUDGEMENTS"
  }
]